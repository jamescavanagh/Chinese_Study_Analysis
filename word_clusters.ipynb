{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install genanki anki ankipandas --index-url https://mirrors.sustech.edu.cn/pypi/simple\n",
    "#!pip install https://huggingface.co/spacy/zh_core_web_trf/resolve/main/zh_core_web_trf-any-py3-none-any.whl\n",
    "#!pip install spacy[transformers,cuda]  --index-url https://mirrors.sustech.edu.cn/pypi/simple\n",
    "\n",
    "import pandas as pd \n",
    "import genanki\n",
    "import anki\n",
    "import ankipandas\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "from thinc.api import set_gpu_allocator, require_gpu\n",
    "#!export CUDA_PATH=\"/usr/lib/cuda\"\n",
    "# Use the GPU, with memory allocations directed via PyTorch.\n",
    "# This prevents out-of-memory errors that would otherwise occur from competing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('zh_core_web_trf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "juneVocab = pd.read_csv('vocabList.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Pinyin</th>\n",
       "      <th>Meaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>打钱</td>\n",
       "      <td>dǎqián</td>\n",
       "      <td>Make money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>汇率</td>\n",
       "      <td>hùilv̀</td>\n",
       "      <td>exchange rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>稳定</td>\n",
       "      <td>wěndìng</td>\n",
       "      <td>Stablize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>股票</td>\n",
       "      <td>gǔpiào</td>\n",
       "      <td>stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>理财投资</td>\n",
       "      <td>lǐcáitóuzī</td>\n",
       "      <td>Financial investment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Characters      Pinyin               Meaning\n",
       "0           0         打钱      dǎqián            Make money\n",
       "1           1         汇率      hùilv̀         exchange rate\n",
       "2           2         稳定     wěndìng              Stablize\n",
       "3           3         股票      gǔpiào                 stock\n",
       "4           4       理财投资  lǐcáitóuzī  Financial investment"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "juneVocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(juneVocab['Characters'].iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('理财', '', 'NOUN', 'NN', 'compound:nn', 'xx', True, False)\n",
      "('投资', '', 'NOUN', 'NN', 'ROOT', 'xx', True, False)\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(((token.text, \n",
    "            token.lemma_, \n",
    "            token.pos_, \n",
    "            token.tag_,\n",
    "            token.dep_,\n",
    "            token.shape_,\n",
    "            token.is_alpha,\n",
    "            token.is_stop,\n",
    "            )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "理财_NN\n",
      "投资_NN\n",
      " 理财/NN 投资/NN\n"
     ]
    }
   ],
   "source": [
    "## Output in different ways\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import collections\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "\n",
    "\n",
    "def read_csv_file():\n",
    "    with open('wordsBackup.csv', 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        #print(reader)\n",
    "        records = ['\\n'.join(row) for row in reader]\n",
    "    return records\n",
    "\n",
    "def write_csv_file(rows):\n",
    "    with open('./wordsBackup.csv', 'w', newline='\\n') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parts of speech tagging\n",
    "for token in doc:\n",
    "    print(((token.text, \n",
    "            token.lemma_, \n",
    "            token.pos_, \n",
    "            token.tag_,\n",
    "            token.dep_,\n",
    "            token.shape_,\n",
    "            token.is_alpha,\n",
    "            token.is_stop,\n",
    "            )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "embedder = #SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = \n",
    "corpus_embeddings = embedder.encode(corpus)\n",
    "\n",
    "# Perform kmean clustering\n",
    "num_clusters = 5\n",
    "clustering_model = KMeans(n_clusters=num_clusters)\n",
    "clustering_model.fit(corpus_embeddings)\n",
    "cluster_assignment = clustering_model.labels_\n",
    "\n",
    "clustered_sentences = [[] for i in range(num_clusters)]\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
    "\n",
    "for i, cluster in enumerate(clustered_sentences):\n",
    "    print(\"Cluster \", i+1)\n",
    "    print(cluster)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_vectors ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jentlejames/anaconda3/envs/unpackAIdev/lib/python3.8/site-packages/spacy/util.py:1648: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
      "  warnings.warn(Warnings.W111)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(310, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a0d539cad6ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mquestion_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert_to_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_of_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unpackAIdev/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \"\"\"\n\u001b[0;32m-> 1030\u001b[0;31m         X = self._validate_data(X, accept_sparse='csr',\n\u001b[0m\u001b[1;32m   1031\u001b[0m                                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                 \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unpackAIdev/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unpackAIdev/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unpackAIdev/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n\u001b[0m\u001b[1;32m    659\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                              % (n_features, array.shape, ensure_min_features,\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(310, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "questions = list(juneVocab['Characters'])\n",
    "nb_of_clusters= 11\n",
    "#clusters= cluster_questions(juneVocab['Characters'], nclusters)\n",
    "question_vectors = [convert_to_vec(question) for question in questions]\n",
    "kmeans = KMeans(n_clusters=nb_of_clusters)\n",
    "kmeans.fit(question_vectors)\n",
    "clusters = collections.defaultdict(list)\n",
    "for i, label in enumerate(kmeans.labels_):\n",
    "    print(i)\n",
    "    clusters[label].append(i)\n",
    "#return(dict(clusters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = convert_to_vec(questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "\n",
    "question_clusters=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2e91f7692891>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clusters' is not defined"
     ]
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-08206322af32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mquestion_clusters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Cluster\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mquestion_clusters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mwrite_csv_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clusters' is not defined"
     ]
    }
   ],
   "source": [
    "question_clusters = []\n",
    "for cluster in range(nclusters):\n",
    "    question_clusters.append([\"Cluster\"+str(cluster+1)+\":\"])\n",
    "    for i,sentence in enumerate(clusters[cluster]):\n",
    "        question_clusters.append([str(questions[sentence])])\n",
    "write_csv_file(question_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster1:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cluster1:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cluster1:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>任务</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>状态</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>思维导图</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Cluster15:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>汇率</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>通货膨胀通胀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>利率</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>利息</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>976 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cluster1:\n",
       "0     Cluster1:\n",
       "1     Cluster1:\n",
       "2            任务\n",
       "3            状态\n",
       "4          思维导图\n",
       "..          ...\n",
       "971  Cluster15:\n",
       "972          汇率\n",
       "973      通货膨胀通胀\n",
       "974          利率\n",
       "975          利息\n",
       "\n",
       "[976 rows x 1 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('wordsBackup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters[11])\n",
    "\n",
    "#for cluster in range(nclusters):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "42\n",
      "63\n",
      "68\n",
      "69\n",
      "93\n",
      "97\n",
      "99\n",
      "100\n",
      "102\n",
      "105\n",
      "119\n",
      "122\n",
      "123\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "138\n",
      "143\n",
      "145\n",
      "146\n",
      "153\n",
      "185\n",
      "new_cluster\n",
      "20\n",
      "24\n",
      "25\n",
      "26\n",
      "33\n",
      "34\n",
      "36\n",
      "37\n",
      "40\n",
      "45\n",
      "50\n",
      "51\n",
      "52\n",
      "55\n",
      "58\n",
      "62\n",
      "72\n",
      "75\n",
      "76\n",
      "84\n",
      "88\n",
      "95\n",
      "101\n",
      "104\n",
      "109\n",
      "113\n",
      "114\n",
      "115\n",
      "117\n",
      "120\n",
      "121\n",
      "124\n",
      "126\n",
      "133\n",
      "134\n",
      "141\n",
      "154\n",
      "157\n",
      "158\n",
      "164\n",
      "168\n",
      "169\n",
      "172\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "186\n",
      "187\n",
      "189\n",
      "190\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "208\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "221\n",
      "222\n",
      "223\n",
      "228\n",
      "241\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "293\n",
      "294\n",
      "309\n",
      "new_cluster\n",
      "131\n",
      "264\n",
      "new_cluster\n",
      "53\n",
      "233\n",
      "278\n",
      "286\n",
      "302\n",
      "new_cluster\n",
      "15\n",
      "161\n",
      "280\n",
      "288\n",
      "new_cluster\n",
      "11\n",
      "30\n",
      "43\n",
      "44\n",
      "71\n",
      "79\n",
      "80\n",
      "82\n",
      "108\n",
      "125\n",
      "136\n",
      "151\n",
      "155\n",
      "162\n",
      "165\n",
      "188\n",
      "219\n",
      "224\n",
      "229\n",
      "239\n",
      "243\n",
      "282\n",
      "289\n",
      "new_cluster\n",
      "0\n",
      "5\n",
      "21\n",
      "23\n",
      "27\n",
      "31\n",
      "47\n",
      "48\n",
      "54\n",
      "56\n",
      "57\n",
      "59\n",
      "60\n",
      "61\n",
      "64\n",
      "67\n",
      "70\n",
      "73\n",
      "74\n",
      "77\n",
      "78\n",
      "81\n",
      "85\n",
      "86\n",
      "87\n",
      "94\n",
      "96\n",
      "103\n",
      "110\n",
      "111\n",
      "112\n",
      "116\n",
      "118\n",
      "132\n",
      "140\n",
      "142\n",
      "148\n",
      "149\n",
      "150\n",
      "152\n",
      "156\n",
      "159\n",
      "163\n",
      "170\n",
      "171\n",
      "173\n",
      "180\n",
      "191\n",
      "207\n",
      "209\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "225\n",
      "226\n",
      "230\n",
      "231\n",
      "232\n",
      "234\n",
      "236\n",
      "237\n",
      "238\n",
      "240\n",
      "269\n",
      "270\n",
      "272\n",
      "273\n",
      "283\n",
      "284\n",
      "285\n",
      "296\n",
      "299\n",
      "300\n",
      "307\n",
      "new_cluster\n",
      "32\n",
      "35\n",
      "38\n",
      "39\n",
      "106\n",
      "107\n",
      "135\n",
      "137\n",
      "139\n",
      "235\n",
      "242\n",
      "266\n",
      "267\n",
      "268\n",
      "274\n",
      "275\n",
      "279\n",
      "281\n",
      "287\n",
      "290\n",
      "291\n",
      "292\n",
      "303\n",
      "304\n",
      "306\n",
      "308\n",
      "new_cluster\n",
      "3\n",
      "4\n",
      "6\n",
      "9\n",
      "10\n",
      "12\n",
      "19\n",
      "28\n",
      "41\n",
      "49\n",
      "83\n",
      "89\n",
      "98\n",
      "144\n",
      "147\n",
      "160\n",
      "166\n",
      "167\n",
      "new_cluster\n",
      "265\n",
      "271\n",
      "276\n",
      "277\n",
      "295\n",
      "297\n",
      "298\n",
      "301\n",
      "305\n",
      "new_cluster\n",
      "46\n",
      "92\n",
      "new_cluster\n",
      "227\n",
      "new_cluster\n",
      "7\n",
      "13\n",
      "22\n",
      "66\n",
      "new_cluster\n",
      "2\n",
      "8\n",
      "16\n",
      "65\n",
      "90\n",
      "91\n",
      "220\n",
      "new_cluster\n",
      "1\n",
      "14\n",
      "17\n",
      "18\n",
      "new_cluster\n"
     ]
    }
   ],
   "source": [
    "for i in range(nclusters):\n",
    "    word_indicies = clusters[i]\n",
    "    for word_idx in word_indicies:\n",
    "        print(word_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Cluster1:'],\n",
       " ['Cluster1:'],\n",
       " ['Cluster1:'],\n",
       " ['任务'],\n",
       " ['状态'],\n",
       " ['思维导图'],\n",
       " ['假设'],\n",
       " ['重复'],\n",
       " ['经历'],\n",
       " ['理论'],\n",
       " ['人际关系'],\n",
       " ['搞人际关系'],\n",
       " ['沟通'],\n",
       " ['产生'],\n",
       " ['观察'],\n",
       " ['信号'],\n",
       " ['心流状态'],\n",
       " ['即兴'],\n",
       " ['即兴创作'],\n",
       " ['即兴演讲'],\n",
       " ['接触即兴'],\n",
       " ['焦虑'],\n",
       " ['无序'],\n",
       " ['过程'],\n",
       " ['解决'],\n",
       " ['后'],\n",
       " ['过程中'],\n",
       " ['Cluster2:'],\n",
       " ['我需要把我的人民币换成美元打到美国的银行卡上'],\n",
       " ['我对他们没有信心'],\n",
       " ['我不相信他们'],\n",
       " ['我担心他们'],\n",
       " ['保守'],\n",
       " ['着急'],\n",
       " ['四点半还醒着'],\n",
       " ['担心'],\n",
       " ['讨好'],\n",
       " ['追求精神的'],\n",
       " ['经济困难的人'],\n",
       " ['污渍'],\n",
       " ['责备'],\n",
       " ['善意的谎话'],\n",
       " ['高级的诚实是用更高级的方式表达真相'],\n",
       " ['打交道'],\n",
       " ['倒了'],\n",
       " ['一模一样'],\n",
       " ['另外'],\n",
       " ['一份工作'],\n",
       " ['意识到'],\n",
       " ['惊讶'],\n",
       " ['局外人'],\n",
       " ['运动会让人的身体产生多巴胺'],\n",
       " ['停车的位置'],\n",
       " ['遇到红灯需要让卡车减速'],\n",
       " ['绕过'],\n",
       " ['耐心'],\n",
       " ['不一定'],\n",
       " ['通常'],\n",
       " ['平常'],\n",
       " ['电焊可以帮我进入心流状态'],\n",
       " ['我需要高度集中注意力'],\n",
       " ['明智的决定'],\n",
       " ['明智的'],\n",
       " ['我妈妈的控制欲很强'],\n",
       " ['吸收新鲜的事物'],\n",
       " ['歧视'],\n",
       " ['才能'],\n",
       " ['非技术性的'],\n",
       " ['未开发的'],\n",
       " ['私人的'],\n",
       " ['遇见对的人是缘分'],\n",
       " ['中国茶文化有很多礼仪这些礼仪往往都伴随着悠久的历史背景所以我们喝茶时需要注意这些礼仪'],\n",
       " ['往往'],\n",
       " ['悠久的历史'],\n",
       " ['今天我们来聊一聊喝茶时需要注意的小细节'],\n",
       " ['中国茶文化绝不仅仅是泡一杯好茶'],\n",
       " ['不仅仅'],\n",
       " ['还伴随着很多茶礼仪'],\n",
       " ['这绝对不是穷讲究'],\n",
       " ['穷讲究'],\n",
       " ['而是在漫长的茶文化发展过程中约定俗成的行为'],\n",
       " ['起码出去喝茶时人家一看知道我们是具备一些茶文化底蕴的'],\n",
       " ['起码至少'],\n",
       " ['而不是任人忽悠的小白'],\n",
       " ['任人'],\n",
       " ['经常有人问倒茶如何回礼很多人用说谢谢或者举杯子扶杯子的方式但是这样的礼节不适用于喝茶通常我们会用叩手礼来作为喝茶回礼'],\n",
       " ['我被问过最多的一个问题就是当别人给我倒茶时我该怎么样去回礼'],\n",
       " ['第一种是说谢谢'],\n",
       " ['说谢谢当然没有问题'],\n",
       " ['可以当你和朋友正聊的热火朝天'],\n",
       " ['我倒茶给你你出于礼貌对我所谢谢'],\n",
       " ['这个时候你和朋友的聊天就被迫中止了'],\n",
       " ['大多数人说完谢谢以后的下一句就是'],\n",
       " ['诶我刚才正在说什么来着我刚才说到哪了'],\n",
       " ['第二种呢是在倒茶时用双手端起杯子'],\n",
       " ['第一这样很烫手'],\n",
       " ['第二万一我手抖的话会把汤汁滴落到你的手上'],\n",
       " ['还有用手去扶杯子也是同理'],\n",
       " ['那我们全国通用的一个手势'],\n",
       " ['回礼的手势就是叩手礼'],\n",
       " ['相传乾隆皇帝下江南微服私访时去到当地一个茶馆'],\n",
       " ['这种茶艺在我国的四川地区至今还很常见'],\n",
       " ['讲究'],\n",
       " ['我爸爸是个讲究人'],\n",
       " ['中国人讲究喝茶'],\n",
       " ['喝茶有很多讲究'],\n",
       " ['我是电脑程序方面的专家'],\n",
       " ['这位医生是心脏方面的专家'],\n",
       " ['她是个情感专家'],\n",
       " ['相似的'],\n",
       " ['小偷偷我的自行车'],\n",
       " ['尝起来'],\n",
       " ['这个菜尝起来很奇怪'],\n",
       " ['茶和咖啡在功能上是相似的'],\n",
       " ['茶和咖啡在功能上很相似'],\n",
       " ['看起来很好吃'],\n",
       " ['像一样'],\n",
       " ['她的歌声听起来像天使一样'],\n",
       " ['听起来好像有小偷'],\n",
       " ['闻起来'],\n",
       " ['你的厨房闻起来好像米其林餐厅'],\n",
       " ['这个香水闻起来有花的香味'],\n",
       " ['这个香水闻起来好像下雨的味道'],\n",
       " ['尝起来'],\n",
       " ['这个菜尝起来很奇怪'],\n",
       " ['这个尝起来像我妈妈做的菜'],\n",
       " ['这个尝起来很地道'],\n",
       " ['收垃圾的'],\n",
       " ['注意力差'],\n",
       " ['相关的'],\n",
       " ['相关的话题'],\n",
       " ['弱'],\n",
       " ['天生'],\n",
       " ['保持个小时的睡眠'],\n",
       " ['Cluster3:'],\n",
       " ['手眼协调'],\n",
       " ['动作'],\n",
       " ['Cluster4:'],\n",
       " ['力量'],\n",
       " ['翅膀'],\n",
       " ['手臂'],\n",
       " ['力量训练'],\n",
       " ['手臂力量'],\n",
       " ['Cluster5:'],\n",
       " ['元宇宙'],\n",
       " ['收入'],\n",
       " ['米'],\n",
       " ['平均温度平均收入'],\n",
       " ['Cluster6:'],\n",
       " ['模型'],\n",
       " ['严格'],\n",
       " ['质量'],\n",
       " ['数量'],\n",
       " ['降温'],\n",
       " ['供给'],\n",
       " ['需求'],\n",
       " ['升职'],\n",
       " ['指标'],\n",
       " ['集中'],\n",
       " ['睡眠质量'],\n",
       " ['绿色食品商店'],\n",
       " ['工程师'],\n",
       " ['移民'],\n",
       " ['土地'],\n",
       " ['具备'],\n",
       " ['核酸检测点'],\n",
       " ['包括'],\n",
       " ['港口'],\n",
       " ['技能'],\n",
       " ['热带地区'],\n",
       " ['器械'],\n",
       " ['平均提高'],\n",
       " ['Cluster7:'],\n",
       " ['打钱'],\n",
       " ['储蓄'],\n",
       " ['电汇'],\n",
       " ['按钮'],\n",
       " ['店面'],\n",
       " ['辩护'],\n",
       " ['分辨'],\n",
       " ['谦虚'],\n",
       " ['谎话'],\n",
       " ['真相'],\n",
       " ['诚实'],\n",
       " ['陷阱'],\n",
       " ['逃跑'],\n",
       " ['土匪'],\n",
       " ['列表'],\n",
       " ['分享'],\n",
       " ['任意'],\n",
       " ['运'],\n",
       " ['线上办公'],\n",
       " ['裁员'],\n",
       " ['解雇'],\n",
       " ['兼职'],\n",
       " ['工作狂'],\n",
       " ['美术馆'],\n",
       " ['展览'],\n",
       " ['研究生'],\n",
       " ['惊喜'],\n",
       " ['多巴胺'],\n",
       " ['停车位'],\n",
       " ['车道'],\n",
       " ['减速'],\n",
       " ['路症'],\n",
       " ['女性朋友'],\n",
       " ['青年旅社'],\n",
       " ['控制欲'],\n",
       " ['导航'],\n",
       " ['人生哲学'],\n",
       " ['幸福感'],\n",
       " ['荔枝'],\n",
       " ['年代'],\n",
       " ['程序员'],\n",
       " ['天赋'],\n",
       " ['第一代'],\n",
       " ['单身'],\n",
       " ['缘分'],\n",
       " ['了解喝茶的入门简单了解茶桌礼仪哔哩哔哩'],\n",
       " ['泡茶'],\n",
       " ['忽悠'],\n",
       " ['叩首礼来源于一个关于乾隆皇帝的故事'],\n",
       " ['店小二行云流水的表演了一套长流壶茶艺'],\n",
       " ['晚辈'],\n",
       " ['长辈'],\n",
       " ['同辈'],\n",
       " ['回礼'],\n",
       " ['居家隔离'],\n",
       " ['居家服'],\n",
       " ['衬衫'],\n",
       " ['海运'],\n",
       " ['运输站'],\n",
       " ['歌声'],\n",
       " ['逼'],\n",
       " ['我妈妈逼我上钢琴课'],\n",
       " ['弹钢琴'],\n",
       " ['小偷'],\n",
       " ['三组俯卧撑'],\n",
       " ['每组个'],\n",
       " ['我每天骑分钟健身单车'],\n",
       " ['跑步机'],\n",
       " ['冲刺'],\n",
       " ['百米冲刺'],\n",
       " ['小孩子'],\n",
       " ['自由泳'],\n",
       " ['姿势很美'],\n",
       " ['仰泳'],\n",
       " ['普拉提'],\n",
       " ['Cluster8:'],\n",
       " ['调情'],\n",
       " ['赖床'],\n",
       " ['病例'],\n",
       " ['症状'],\n",
       " ['心理健康'],\n",
       " ['抑郁症'],\n",
       " ['睡眠'],\n",
       " ['失眠'],\n",
       " ['青少年'],\n",
       " ['舞蹈'],\n",
       " ['细菌'],\n",
       " ['训练胸部肌肉'],\n",
       " ['训练有氧的能力'],\n",
       " ['无氧训练'],\n",
       " ['心肌'],\n",
       " ['心肺'],\n",
       " ['身高'],\n",
       " ['体重'],\n",
       " ['平均地训练肌肉群语法'],\n",
       " ['腹部肌肉'],\n",
       " ['腹肌'],\n",
       " ['卧推'],\n",
       " ['引体向上'],\n",
       " ['举重'],\n",
       " ['部位'],\n",
       " ['瑜伽球'],\n",
       " ['Cluster9:'],\n",
       " ['股票'],\n",
       " ['理财投资'],\n",
       " ['长期投资'],\n",
       " ['行业'],\n",
       " ['新兴产业'],\n",
       " ['基金'],\n",
       " ['分行'],\n",
       " ['市场'],\n",
       " ['企业文化'],\n",
       " ['积极'],\n",
       " ['创业公司'],\n",
       " ['职业方向'],\n",
       " ['企业文化'],\n",
       " ['创业'],\n",
       " ['长远'],\n",
       " ['职位'],\n",
       " ['发展'],\n",
       " ['开发'],\n",
       " ['Cluster10:'],\n",
       " ['俯卧撑'],\n",
       " ['健身单车'],\n",
       " ['有氧运动'],\n",
       " ['椭圆机'],\n",
       " ['泳姿'],\n",
       " ['蛙泳'],\n",
       " ['蝶泳'],\n",
       " ['划船机'],\n",
       " ['健美'],\n",
       " ['Cluster11:'],\n",
       " ['经验'],\n",
       " ['经验'],\n",
       " ['Cluster12:'],\n",
       " ['行李箱'],\n",
       " ['Cluster13:'],\n",
       " ['交易策略'],\n",
       " ['政策'],\n",
       " ['策略'],\n",
       " ['思路'],\n",
       " ['Cluster14:'],\n",
       " ['稳定'],\n",
       " ['风险'],\n",
       " ['骗局'],\n",
       " ['过滤'],\n",
       " ['数据分析'],\n",
       " ['数据分析师'],\n",
       " ['专家'],\n",
       " ['Cluster15:'],\n",
       " ['汇率'],\n",
       " ['通货膨胀通胀'],\n",
       " ['利率'],\n",
       " ['利息']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b35736f271ae3a6547f08ef3ad12296102f5e6031b2a7c6493a7e5cc9f313275"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('unpackAIdev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
