{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chinese Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Data from Tutor Session Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install instruction\n",
    "\n",
    "conda create -n ChineseAutomation\n",
    "conda update -n base -c defaults conda\n",
    "conda install ipykernel\n",
    "\n",
    "# Library installs\n",
    "!pip install -qq pinyin pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -n ChineseAutomation ipykernel --update-deps --force-reinstall\n",
    "!pip install -qq pinyin pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from xml.etree import ElementTree\n",
    "import datetime, time\n",
    "\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting XML File of Tutoring Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_most_recent_ompl():\n",
    "    \"\"\"\n",
    "    Searches for .opml files in downloads directory\n",
    "    Finds the one with the most recent time stamp \n",
    "    \n",
    "    returns Path Object\n",
    "\n",
    "    \"\"\"\n",
    "    # Finds the downloads directory\n",
    "    pathDir = Path(os.path.join(os.path.expanduser('~'),'Downloads'))\n",
    "\n",
    "    opmlFileList = []\n",
    "\n",
    "    # fetches all opml files\n",
    "\n",
    "    for file in os.listdir(pathDir):\n",
    "        if file.endswith('.opml'):\n",
    "            opmlFileList.append(file)\n",
    "\n",
    "    # Sorts them by timestamp, get the index of most recent file\n",
    "\n",
    "    timestampPattern = re.compile(r'[0-9]{6}\\-[0-9]{6}')\n",
    "\n",
    "    fileTimestamps = []\n",
    "    stringToDatetimePattern = \"%y%m%d-%H%M%S\"\n",
    "\n",
    "    for file in opmlFileList:\n",
    "        #Uses Regex to parse timestamp pattern\n",
    "        \n",
    "        timestamp = re.search(timestampPattern, file)[0]\n",
    "        timestamp = time.mktime(datetime.datetime.strptime(timestamp, stringToDatetimePattern).timetuple())\n",
    "        fileTimestamps.append(timestamp)\n",
    "\n",
    "    # Sorts the highest timestamp \n",
    "    mostRecent = max(fileTimestamps)\n",
    "    mostRecentIdx = fileTimestamps.index(mostRecent)\n",
    "\n",
    "    return pathDir/opmlFileList[mostRecentIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostRecentNotesPath = find_most_recent_ompl()\n",
    "\n",
    "with open(mostRecentNotesPath, 'rt') as f:\n",
    "        tree = ElementTree.parse(f)\n",
    "\n",
    "notesRoot = tree.getroot()\n",
    "\n",
    "notesBody = notesRoot.find('body')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese\n",
      "好好学习，天天上上\n",
      "SOP for different times, lesson plans\n"
     ]
    }
   ],
   "source": [
    "# Finds the XML Element that contains\n",
    "# My Chinese Tutoring Notes\n",
    "\n",
    "\n",
    "# Finds Base Element\n",
    "chineseBaseElem = None\n",
    "for elem in notesBody:\n",
    "    #print(elem.attrib['text'])\n",
    "    if elem.attrib['text'] == 'Focus Points':\n",
    "        outerElem1 = elem\n",
    "        #print(outerElem1.attrib['text'])\n",
    "\n",
    "# Drills deeper\n",
    "for elem in outerElem1:\n",
    "    #rint(elem.attrib['text'])\n",
    "    if elem.attrib['text'].strip() == 'Chinese':\n",
    "        #print(True)\n",
    "        outerElem2 = elem\n",
    "        print(outerElem2.attrib['text'])\n",
    "#print(chineseBaseElem.text)\n",
    "# Finds the part with the tutoring notes \n",
    "for elem in outerElem2:\n",
    "    print(elem.attrib['text'])\n",
    "    if elem.attrib['text'].strip() == '好好学习，天天上上':\n",
    "        chineseBaseElem = elem\n",
    "\n",
    "# This avoids parsing through the rest of the data \n",
    "# that is exported by my workflowy app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好好学习，天天上上'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chineseBaseElem.attrib['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study Plans\n",
      "videos \n",
      "Categories\n",
      "Inbox\n",
      "Tutor Session Notes\n",
      "社交平台 she4 jiao1 ping2 tai2\n"
     ]
    }
   ],
   "source": [
    "# Here I want to know what category I gave\n",
    "# The Vocabulary with manual assignment\n",
    "\n",
    "# Also needs to know the raw notes by the date\n",
    "# they were recorded\n",
    "\n",
    "vocabCategoriesBaseElem = None\n",
    "tutorSessionNotesBaseElem = None\n",
    "\n",
    "for elem in chineseBaseElem:\n",
    "    print(elem.attrib['text'])\n",
    "    if elem.attrib['text'] == 'Categories':\n",
    "        vocabCategoriesBaseElem = elem\n",
    "    elif elem.attrib['text'] == 'Tutor Session Notes':\n",
    "        tutorSessionNotesBaseElem = elem\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Extracting XML Data into a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal here is to extract the notes from each\n",
    "# Tutoring Session by date with a list of \n",
    "# Each of the elements that contain them\n",
    "\n",
    "\n",
    "# Looks for element text which matches internal \n",
    "# workflowy pattern in opml \n",
    "timePattern = re.compile('time startYear')\n",
    "\n",
    "elementsByDate = []\n",
    "elementsDateAdded = []\n",
    "\n",
    "# Checks for elements which contain dates\n",
    "# Which will contain sub elements with vocab\n",
    "# Appends them to a list, along with the dates\n",
    "# From before\n",
    "for outline in tutorSessionNotesBaseElem.iter():\n",
    "\n",
    "    text = outline.attrib['text']\n",
    "    \n",
    "    #Extracts the Date \n",
    "    # finds new nodes\n",
    "    \n",
    "    hasTime = re.search(timePattern,text)\n",
    "    \n",
    "    if hasTime:\n",
    "        #Extracting datetime info\n",
    "        time = text.split()\n",
    "        year = time[1].split('\\\"')[1]\n",
    "        month = time[2].split('\\\"')[1]\n",
    "        day = time[3].split('\\\"')[1]\n",
    "        dateAdded = year+' '+month +' '+day\n",
    "        #print(dateAdded)\n",
    "        \n",
    "        elementsByDate.append(outline)\n",
    "        elementsDateAdded.append(dateAdded)\n",
    "    else:\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorSession = elementsByDate[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find if a character is Chinese\n",
    "def is_cjk(char):\n",
    "    char = ord(char)\n",
    "    cjk_ranges = [\n",
    "    (0x4E00,  0x62FF),\n",
    "    (0x6300,  0x77FF),\n",
    "    (0x7800,  0x8CFF),\n",
    "    (0x8D00,  0x9FCC),\n",
    "    (0x3400,  0x4DB5),\n",
    "    (0x20000, 0x215FF),\n",
    "    (0x21600, 0x230FF),\n",
    "    (0x23100, 0x245FF),\n",
    "    (0x24600, 0x260FF),\n",
    "    (0x26100, 0x275FF),\n",
    "    (0x27600, 0x290FF),\n",
    "    (0x29100, 0x2A6DF),\n",
    "    (0x2A700, 0x2B734),\n",
    "    (0x2B740, 0x2B81D),\n",
    "    (0x2B820, 0x2CEAF),\n",
    "    (0x2CEB0, 0x2EBEF),\n",
    "    (0x2F800, 0x2FA1F), ]\n",
    "    \n",
    "    \n",
    "    for bottom, top in cjk_ranges:\n",
    "        if char >= bottom and char <= top:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "pinyinRegex = re.compile(r\"^(?P<initial>ch|zh|sh|r|c|b|d|g|f|h|k|j|m|l|n|q|p|s|t|w|y|x|z|)(?P<final>(?:(?<=ch)uang|(?<=ch)ang|(?<=ch)eng|(?<=ch)ong|(?<=ch)uai|(?<=ch)uan|(?<=ch)ai|(?<=ch)an|(?<=ch)ao|(?<=ch)en|(?<=ch)ou|(?<=ch)ua|(?<=ch)ui|(?<=ch)un|(?<=ch)uo|(?<=ch)a|(?<=ch)e|(?<=ch)i|(?<=ch)u)|(?:(?<=zh)uang|(?<=zh)ang|(?<=zh)eng|(?<=zh)ong|(?<=zh)uai|(?<=zh)uan|(?<=zh)ai|(?<=zh)an|(?<=zh)ao|(?<=zh)ei|(?<=zh)en|(?<=zh)ou|(?<=zh)ua|(?<=zh)ui|(?<=zh)un|(?<=zh)uo|(?<=zh)a|(?<=zh)e|(?<=zh)i|(?<=zh)u)|(?:(?<=sh)uang|(?<=sh)ang|(?<=sh)eng|(?<=sh)uai|(?<=sh)uan|(?<=sh)ai|(?<=sh)an|(?<=sh)ao|(?<=sh)ei|(?<=sh)en|(?<=sh)ou|(?<=sh)ua|(?<=sh)ui|(?<=sh)un|(?<=sh)uo|(?<=sh)a|(?<=sh)e|(?<=sh)i|(?<=sh)u)|(?:(?<=c)ang|(?<=c)eng|(?<=c)ong|(?<=c)uan|(?<=c)ai|(?<=c)an|(?<=c)ao|(?<=c)en|(?<=c)ou|(?<=c)ui|(?<=c)un|(?<=c)uo|(?<=c)a|(?<=c)e|(?<=c)i|(?<=c)u)|(?:(?<=b)ang|(?<=b)eng|(?<=b)ian|(?<=b)iao|(?<=b)ing|(?<=b)ai|(?<=b)an|(?<=b)ao|(?<=b)ei|(?<=b)en|(?<=b)ie|(?<=b)in|(?<=b)a|(?<=b)i|(?<=b)o|(?<=b)u)|(?:(?<=d)ang|(?<=d)eng|(?<=d)ian|(?<=d)iao|(?<=d)ing|(?<=d)ong|(?<=d)uan|(?<=d)ai|(?<=d)an|(?<=d)ao|(?<=d)ei|(?<=d)en|(?<=d)ia|(?<=d)ie|(?<=d)iu|(?<=d)ou|(?<=d)ui|(?<=d)un|(?<=d)uo|(?<=d)a|(?<=d)e|(?<=d)i|(?<=d)u)|(?:(?<=g)uang|(?<=g)ang|(?<=g)eng|(?<=g)ong|(?<=g)uai|(?<=g)uan|(?<=g)ai|(?<=g)an|(?<=g)ao|(?<=g)ei|(?<=g)en|(?<=g)ou|(?<=g)ua|(?<=g)ui|(?<=g)un|(?<=g)uo|(?<=g)a|(?<=g)e|(?<=g)u)|(?:(?<=f)ang|(?<=f)eng|(?<=f)iao|(?<=f)an|(?<=f)ei|(?<=f)en|(?<=f)ou|(?<=f)a|(?<=f)o|(?<=f)u)|(?:(?<!sh|ch|zh)(?<=h)uang|(?<!sh|ch|zh)(?<=h)ang|(?<!sh|ch|zh)(?<=h)eng|(?<!sh|ch|zh)(?<=h)ong|(?<!sh|ch|zh)(?<=h)uai|(?<!sh|ch|zh)(?<=h)uan|(?<!sh|ch|zh)(?<=h)ai|(?<!sh|ch|zh)(?<=h)an|(?<!sh|ch|zh)(?<=h)ao|(?<!sh|ch|zh)(?<=h)ei|(?<!sh|ch|zh)(?<=h)en|(?<!sh|ch|zh)(?<=h)ou|(?<!sh|ch|zh)(?<=h)ua|(?<!sh|ch|zh)(?<=h)ui|(?<!sh|ch|zh)(?<=h)un|(?<!sh|ch|zh)(?<=h)uo|(?<!sh|ch|zh)(?<=h)a|(?<!sh|ch|zh)(?<=h)e|(?<!sh|ch|zh)(?<=h)u)|(?:(?<=k)uang|(?<=k)ang|(?<=k)eng|(?<=k)ong|(?<=k)uai|(?<=k)uan|(?<=k)ai|(?<=k)an|(?<=k)ao|(?<=k)en|(?<=k)ou|(?<=k)ua|(?<=k)ui|(?<=k)un|(?<=k)uo|(?<=k)a|(?<=k)e|(?<=k)u)|(?:(?<=j)iang|(?<=j)iong|(?<=j)ian|(?<=j)iao|(?<=j)ing|(?<=j)üan|(?<=j)ia|(?<=j)ie|(?<=j)in|(?<=j)iu|(?<=j)üe|(?<=j)ün|(?<=j)i|(?<=j)ü)|(?:(?<=m)ang|(?<=m)eng|(?<=m)ian|(?<=m)iao|(?<=m)ing|(?<=m)ai|(?<=m)an|(?<=m)ao|(?<=m)ei|(?<=m)en|(?<=m)ie|(?<=m)in|(?<=m)iu|(?<=m)ou|(?<=m)a|(?<=m)e|(?<=m)i|(?<=m)o|(?<=m)u)|(?:(?<=l)iang|(?<=l)ang|(?<=l)eng|(?<=l)ian|(?<=l)iao|(?<=l)ing|(?<=l)ong|(?<=l)uan|(?<=l)ai|(?<=l)an|(?<=l)ao|(?<=l)ei|(?<=l)ia|(?<=l)ie|(?<=l)in|(?<=l)iu|(?<=l)ou|(?<=l)un|(?<=l)uo|(?<=l)üe|(?<=l)a|(?<=l)e|(?<=l)i|(?<=l)o|(?<=l)u|(?<=l)ü)|(?:(?<=n)iang|(?<=n)ang|(?<=n)eng|(?<=n)ian|(?<=n)iao|(?<=n)ing|(?<=n)ong|(?<=n)uan|(?<=n)ai|(?<=n)an|(?<=n)ao|(?<=n)ei|(?<=n)en|(?<=n)ie|(?<=n)in|(?<=n)iu|(?<=n)ou|(?<=n)un|(?<=n)uo|(?<=n)üe|(?<=n)a|(?<=n)e|(?<=n)i|(?<=n)u|(?<=n)ü)|(?:(?<=q)iang|(?<=q)iong|(?<=q)ian|(?<=q)iao|(?<=q)ing|(?<=q)üan|(?<=q)ia|(?<=q)ie|(?<=q)in|(?<=q)iu|(?<=q)üe|(?<=q)ün|(?<=q)i|(?<=q)ü)|(?:(?<=p)ang|(?<=p)eng|(?<=p)ian|(?<=p)iao|(?<=p)ing|(?<=p)ai|(?<=p)an|(?<=p)ao|(?<=p)ei|(?<=p)en|(?<=p)ie|(?<=p)in|(?<=p)ou|(?<=p)a|(?<=p)i|(?<=p)o|(?<=p)u)|(?:(?<=s)ang|(?<=s)eng|(?<=s)ong|(?<=s)uan|(?<=s)ai|(?<=s)an|(?<=s)ao|(?<=s)en|(?<=s)ou|(?<=s)ui|(?<=s)un|(?<=s)uo|(?<=s)a|(?<=s)e|(?<=s)i|(?<=s)u)|(?:(?<=r)ang|(?<=r)eng|(?<=r)ong|(?<=r)uan|(?<=r)an|(?<=r)ao|(?<=r)en|(?<=r)ou|(?<=r)ua|(?<=r)ui|(?<=r)un|(?<=r)uo|(?<=r)e|(?<=r)i|(?<=r)u)|(?:(?<=t)ang|(?<=t)eng|(?<=t)ian|(?<=t)iao|(?<=t)ing|(?<=t)ong|(?<=t)uan|(?<=t)ai|(?<=t)an|(?<=t)ao|(?<=t)ei|(?<=t)ie|(?<=t)ou|(?<=t)ui|(?<=t)un|(?<=t)uo|(?<=t)a|(?<=t)e|(?<=t)i|(?<=t)u)|(?:(?<=w)ang|(?<=w)eng|(?<=w)ai|(?<=w)an|(?<=w)ei|(?<=w)en|(?<=w)a|(?<=w)o|(?<=w)u)|(?:(?<=y)ang|(?<=y)ing|(?<=y)ong|(?<=y)uan|(?<=y)ai|(?<=y)an|(?<=y)ao|(?<=y)in|(?<=y)ou|(?<=y)ue|(?<=y)un|(?<=y)a|(?<=y)e|(?<=y)e|(?<=y)i|(?<=y)o|(?<=y)u)|(?:(?<=x)iang|(?<=x)iong|(?<=x)ian|(?<=x)iao|(?<=x)ing|(?<=x)üan|(?<=x)ia|(?<=x)ie|(?<=x)in|(?<=x)iu|(?<=x)üe|(?<=x)ün|(?<=x)i|(?<=x)ü)|(?:(?<=z)ang|(?<=z)eng|(?<=z)ong|(?<=z)uan|(?<=z)ai|(?<=z)an|(?<=z)ao|(?<=z)ei|(?<=z)en|(?<=z)ou|(?<=z)ui|(?<=z)un|(?<=z)uo|(?<=z)a|(?<=z)e|(?<=z)i|(?<=z)u)|(?:(?<!r|c|b|d|g|f|h|k|j|m|l|n|q|p|s|t|w|y|x|z)a|(?<!r|c|b|d|g|f|h|k|j|m|l|n|q|p|s|t|w|y|x|z)ai|(?<!r|c|b|d|g|f|h|k|j|m|l|n|q|p|s|t|w|y|x|z)an|(?<!r|c|b|d|g|f|h|k|j|m|l|n|q|p|s|t|w|y|x|z)ang|(?<!r|c|b|d|g|f|h|k|j|m|l|n|q|p|s|t|w|y|x|z)ao|(?<!r|c|b|d|g|f|h|k|j|m|l|n|q|p|s|t|w|y|x|z)e|(?<!r|c|b|d|g|f|h|k|j|m|l|n|q|p|s|t|w|y|x|z)ei|(?<!r|c|b|d|g|f|h|k|j|m|l|n|q|p|s|t|w|y|x|z)en|(?<!r|c|b|d|g|f|h|k|j|m|l|n|q|p|s|t|w|y|x|z)eng|(?<!r|c|b|d|g|f|h|k|j|m|l|n|q|p|s|t|w|y|x|z)er|(?<!r|c|b|d|g|f|h|k|j|m|l|n|q|p|s|t|w|y|x|z)o|(?<!r|c|b|d|g|f|h|k|j|m|l|n|q|p|s|t|w|y|x|z)ou))$\")\n",
    "\n",
    "#pinyinRegex = r'(miu|[pm]ou|[bpm](o|e(i|ng?)?|a(ng?|i|o)?|i(e|ng?|a[no])?|u))|(f(ou?|[ae](ng?|i)?|u))|(d(e(i|ng?)|i(a[on]?|u))|[dt](a(i|ng?|o)?|e(i|ng)?|i(a[on]?|e|ng|u)?|o(ng?|u)|u(o|i|an?|n)?))|(neng?|[ln](a(i|ng?|o)?|e(i|ng)?|i(ang|a[on]?|e|ng?|u)?|o(ng?|u)|u(o|i|an?|n)?|ve?))|([ghk](a(i|ng?|o)?|e(i|ng?)?|o(u|ng)|u(a(i|ng?)?|i|n|o)?))|(z[h]?ei|[cz]hua(i|ng?)?|[cz][h]?(a(i|ng?|o)?|en?g?|o(u|ng)?|u(a?n|o|i)?|(e|i)))|(song|shua(i|ng?)?|shei|s[h]?(a(i|ng?|o)?|en?g?|ou|u(a?n|o|i)?|i))|(r([ae]ng?|i|e|ao|ou|ong|u[oin]|ua?n?))|([jqx](i(a(o|ng?)?|[eu]|ong|ng?)?|u(e|a?n)?))|(wu|w?(a(i|o|ng?)?|ou?|e(i|ng?)?))|y(a(o|ng?)?|e|in?g?|o(u|ng)?|u(e|a?n)?[1234]?)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_cn_chars_from_indv_session(tutorSession):\n",
    "    \n",
    "    \n",
    "    ChineseCharactersInNotes = []\n",
    "    # Extracts the Chinese Characters one by one\n",
    "    # From the raw text\n",
    "    for tutorsNote in tutorSession.iter():\n",
    "        rawText = tutorsNote.attrib['text']\n",
    "        #print(rawText)\n",
    "        chineseCharacters = ''\n",
    "        for char in rawText:\n",
    "            if is_cjk(char):\n",
    "                chineseCharacters += char\n",
    "        #print(len(chineseCharacters))\n",
    "        \n",
    "        ### Print test to find notes \n",
    "        #   that don't contain CN Characters\n",
    "        # \n",
    "        #if len(chineseCharacters) == 0:\n",
    "        #    print(rawText)\n",
    "\n",
    "        ChineseCharactersInNotes.append(chineseCharacters)\n",
    "        #print(chineseCharacters)\n",
    "    # Checks for pinyin\n",
    "    ChineseCharactersInNotes = [i for i in ChineseCharactersInNotes if i]\n",
    "\n",
    "    return ChineseCharactersInNotes\n",
    "    #pinyinInNote = re.findall(pinyinRegex,rawText)\n",
    "    #pinyinInNote = re.search(r'[a-z]*[1234]?',tutorsNote)\n",
    "    \n",
    "    #print(pinyinInNote)\n",
    "\n",
    "\n",
    "    #for subNote in tutorsNote:\n",
    "        #print('//')\n",
    "        #print(subNote.attrib['text'])\n",
    "        #print(subNote.attrib['text'])\n",
    "\n",
    "    ### Needs to check for the likelyhood that\n",
    "    # # it is pinyin or not    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '2', '2', '2', '2', '2', '2']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['3'] + 6 * ['2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561\n"
     ]
    }
   ],
   "source": [
    "ChineseVocabColumn = []\n",
    "dateColumn = []\n",
    "\n",
    "for date, elem in enumerate(elementsByDate):\n",
    "    #print(elementsDateAdded[date])\n",
    "    cnVocabFromSession = extract_cn_chars_from_indv_session(elem)\n",
    "    \n",
    "    \n",
    "    dateColumn = dateColumn + len(cnVocabFromSession) * [elementsDateAdded[date]]\n",
    "    ChineseVocabColumn = ChineseVocabColumn + cnVocabFromSession\n",
    "print(len(ChineseVocabColumn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnVocabularyDF = pd.DataFrame({'Vocab':ChineseVocabColumn,\n",
    "                                'Date':dateColumn })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnVocabularyDF.to_csv('./data/initialExtractVocabAndDateAdded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ChineseAutomation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7980743aae653ac9739fb934e04ede1c780f22bb2ac4dedf609626bec8781b4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
