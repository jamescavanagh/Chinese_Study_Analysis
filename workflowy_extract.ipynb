{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pinyin\n",
    "import translators\n",
    "from xml.etree import ElementTree\n",
    "import datetime, time\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PathForNotes = Path('/home/jentlejames/Downloads') \n",
    "main_vocab_df = pd.read_csv('./vocab_master.csv',index_col=0)\n",
    "\n",
    "# Target for automation\n",
    "#fileName = 'WF - Notes - 220722-110837.opml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_most_recent_ompl(base_dir):\n",
    "    opmlFileList = []\n",
    "\n",
    "    # fetches all opml files\n",
    "\n",
    "    for file in os.listdir(base_dir):\n",
    "        if file.endswith('.opml'):\n",
    "            opmlFileList.append(file)\n",
    "\n",
    "    # Sorts them by timestamp, get the index of most recent file\n",
    "\n",
    "    timestampPattern = re.compile(r'[0-9]{6}\\-[0-9]{6}')\n",
    "\n",
    "    fileTimestamps = []\n",
    "    stringToDatetimePattern = \"%y%m%d-%H%M%S\"\n",
    "\n",
    "    for file in opmlFileList:\n",
    "        timestamp = re.search(timestampPattern, file)[0]\n",
    "        timestamp = time.mktime(datetime.datetime.strptime(timestamp, stringToDatetimePattern).timetuple())\n",
    "        fileTimestamps.append(timestamp)\n",
    "\n",
    "    mostRecent = max(fileTimestamps)\n",
    "    mostRecentIdx = fileTimestamps.index(mostRecent)\n",
    "\n",
    "    return base_dir/opmlFileList[mostRecentIdx]\n",
    "\n",
    "\n",
    "# Chinese Japanese Character Ranges\n",
    "# Functions\n",
    "\n",
    "def is_cjk(char):\n",
    "    char = ord(char)\n",
    "    cjk_ranges = [\n",
    "    (0x4E00,  0x62FF),\n",
    "    (0x6300,  0x77FF),\n",
    "    (0x7800,  0x8CFF),\n",
    "    (0x8D00,  0x9FCC),\n",
    "    (0x3400,  0x4DB5),\n",
    "    (0x20000, 0x215FF),\n",
    "    (0x21600, 0x230FF),\n",
    "    (0x23100, 0x245FF),\n",
    "    (0x24600, 0x260FF),\n",
    "    (0x26100, 0x275FF),\n",
    "    (0x27600, 0x290FF),\n",
    "    (0x29100, 0x2A6DF),\n",
    "    (0x2A700, 0x2B734),\n",
    "    (0x2B740, 0x2B81D),\n",
    "    (0x2B820, 0x2CEAF),\n",
    "    (0x2CEB0, 0x2EBEF),\n",
    "    (0x2F800, 0x2FA1F), ]\n",
    "    \n",
    "    \n",
    "    for bottom, top in cjk_ranges:\n",
    "        if char >= bottom and char <= top:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Adds new words\n",
    "def new_vocab_df_generator(elem):\n",
    "    \"\"\"_summary_\n",
    "    \n",
    "    Takes in an xml element, returns a dataframe of the chinese characters in each element\n",
    "    along with the date\n",
    "    \n",
    "    Added\n",
    "    \n",
    "    Args:\n",
    "        elem (_type_): _description_\n",
    "        xml element, expected to be in the opml format from workflowy\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    #vocab_df = pd.DataFrame({}, columns=['Characters', 'Date'])\n",
    "\n",
    "    vocabFromCat = []\n",
    "    catName = elem.attrib['text']\n",
    "    for lessonNotes in elem.iter():\n",
    "        # print(elementsDateAdded[i])\n",
    "        \n",
    "        for note in lessonNotes:\n",
    "            #print(note)\n",
    "            noteText = note.attrib['text']\n",
    "\n",
    "            chineseCharacters = ''\n",
    "\n",
    "            for char in noteText:\n",
    "                if is_cjk(char):\n",
    "                    chineseCharacters += char\n",
    "\n",
    "            vocabFromCat.append(chineseCharacters)\n",
    "\n",
    "        # Generates a column of same shape as vocab\n",
    "        #dateColumn = [elementsDateAdded[i]] * len(vocabFromLesson)\n",
    "        \n",
    "        #lessonDictionary = dict(zipvocabFromLesson)\n",
    "        catCol = [catName] * len(vocabFromCat)\n",
    "        #catDictionary = dict(zip(vocabFromCat,catCol))\n",
    "        tmp_df = pd.DataFrame({'Characters':vocabFromCat,\n",
    "                               'Cat':catCol},dtype='object')\n",
    "        print(tmp_df.shape)\n",
    "        return tmp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jentlejames/Downloads/WF - Export - 220725-132311.opml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######### BEGIN PROGRAM ############\n",
    "\n",
    "fileName = find_most_recent_ompl(PathForNotes)\n",
    "print(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #sys.argv[1]\n",
    "\n",
    "\n",
    "with open(fileName, 'rt') as f:\n",
    "        tree = ElementTree.parse(f)\n",
    "\n",
    "notesRoot = tree.getroot()\n",
    "\n",
    "notesBody = notesRoot.find('body')\n",
    "#outlineRoot = notesBody.find('outline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@unpackAI @ryzomatic #daily #easywin #elan\n",
      "To Do Matrix\n",
      "Inbox\n",
      "Life Aspirations\n",
      "\n",
      "Schedule\n",
      "Focus Points\n",
      "other\n",
      "Inbox\n",
      "Daily Routines\n",
      "UnpackAI\n",
      " Elan #elan\n",
      "Chinese\n",
      "ORCA\n",
      "Notes\n",
      "On Deck\n",
      "Matrix\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chineseBaseElem = None\n",
    "for elem in notesBody:\n",
    "    #print(elem.attrib['text'])\n",
    "    if elem.attrib['text'] == 'Focus Points':\n",
    "        chineseBaseElem = elem\n",
    "\n",
    "for elem in chineseBaseElem:\n",
    "    print(elem.attrib['text'])\n",
    "    if elem.attrib['text'] == 'Chinese':\n",
    "        chineseBaseElem = elem\n",
    "\n",
    "for elem in chineseBaseElem:\n",
    "    print(elem.text)\n",
    "    if elem.attrib['text'] == '好好学习，天天上上':\n",
    "        chineseBaseElem = elem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study Plans\n",
      "videos \n",
      "Categories\n",
      "Inbox\n",
      "Tutor Session Notes\n",
      "社交平台 she4 jiao1 ping2 tai2\n"
     ]
    }
   ],
   "source": [
    "vocabCategoriesBaseElem = None\n",
    "tutorSessionNotesBaseElem = None\n",
    "\n",
    "for elem in chineseBaseElem:\n",
    "    #print(elem.attrib['text'])\n",
    "    if elem.attrib['text'] == 'Categories':\n",
    "        vocabCategoriesBaseElem = elem\n",
    "    elif elem.attrib['text'] == 'Tutor Session Notes':\n",
    "        tutorSessionNotesBaseElem = elem\n",
    "    else:\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'outline' at 0x70831c337220>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tutorSessionNotesBaseElem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabCats = []\n",
    "categoryPattern = re.compile('Cat\\s[0-9]*')\n",
    "\n",
    "for elem in vocabCategoriesBaseElem:\n",
    "    \n",
    "    if re.search(categoryPattern, elem.attrib['text'][:5]):\n",
    "        vocabCats.append(elem)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cat 1 (Tech & Electronics) Work'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabCats[0].attrib['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 2)\n",
      "(88, 2)\n",
      "(103, 2)\n",
      "(102, 2)\n",
      "(0, 2)\n"
     ]
    }
   ],
   "source": [
    "cat_df = pd.DataFrame({},columns=['Characters','Cat'])\n",
    "\n",
    "for category in vocabCats:\n",
    "    tmp_df = new_vocab_df_generator(category)\n",
    "    \n",
    "    cat_df = pd.concat([cat_df,tmp_df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df['Pinyin'] = cat_df['Characters'].apply(lambda letters: pinyin.get(letters))\n",
    "\n",
    "# Calls Google Translate API to translate new vocab\n",
    "definitions = []\n",
    "for term in cat_df['Characters'].iteritems():\n",
    "    # Slow calls \n",
    "    definition = translators.google(term[1],from_language='zh-CN',to_language='en')\n",
    "    definitions.append(definition)\n",
    "cat_df['Meaning'] = definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df.to_csv('categories_main.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Looks for element text which matches internal \n",
    "# workflowy pattern in opml \n",
    "timePattern = re.compile('time startYear')\n",
    "\n",
    "# Creating list of elements\n",
    "# Which contain lesson notes \n",
    "elementsByDate = []\n",
    "elementsDateAdded = []\n",
    "\n",
    "\n",
    "# Checks for elements which contain dates\n",
    "# Which will contain sub elements with vocab\n",
    "# Appends them to a list, along with the dates\n",
    "# From before\n",
    "for outline in tutorSessionNotesBaseElem.iter():\n",
    "\n",
    "    text = outline.attrib['text']\n",
    "    \n",
    "    #Extracts the Date \n",
    "    # finds new nodes\n",
    "    \n",
    "    hasTime = re.search(timePattern,text)\n",
    "    \n",
    "    if hasTime:\n",
    "        #Extracting datetime info\n",
    "        time = text.split()\n",
    "        year = time[1].split('\\\"')[1]\n",
    "        month = time[2].split('\\\"')[1]\n",
    "        day = time[3].split('\\\"')[1]\n",
    "        dateAdded = year+' '+month +' '+day\n",
    "        #print(dateAdded)\n",
    "        \n",
    "        elementsByDate.append(outline)\n",
    "        elementsDateAdded.append(dateAdded)\n",
    "    else:\n",
    "        continue \n",
    "\n",
    "#print(elementsByDate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'outline' at 0x70831c337270>,\n",
       " <Element 'outline' at 0x70831c33c090>,\n",
       " <Element 'outline' at 0x70831c33c680>,\n",
       " <Element 'outline' at 0x70831c2c51d0>,\n",
       " <Element 'outline' at 0x70831c2c5ae0>,\n",
       " <Element 'outline' at 0x70831c2d34f0>,\n",
       " <Element 'outline' at 0x70831c2d3ef0>,\n",
       " <Element 'outline' at 0x70831c2d8950>,\n",
       " <Element 'outline' at 0x70831c2d8bd0>,\n",
       " <Element 'outline' at 0x70831c2d8f40>,\n",
       " <Element 'outline' at 0x70831c2e5b80>,\n",
       " <Element 'outline' at 0x70831c2ebef0>,\n",
       " <Element 'outline' at 0x70831c2ef630>,\n",
       " <Element 'outline' at 0x70831c2efe50>,\n",
       " <Element 'outline' at 0x70831c28c450>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elementsByDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorSessionDateSeries = pd.to_datetime(elementsDateAdded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Characters</th>\n",
       "      <th>Date</th>\n",
       "      <th>Pinyin</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Characters, Date, Pinyin, Meaning, cluster]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_vocab_df[main_vocab_df['Date'].isin(tutorSessionDateSeries) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newSessions = pd.Series(tutorSessionDateSeries[~tutorSessionDateSeries.isin(main_vocab_df.Date.unique())])\n",
    "# Fill this up automatically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-08\n",
      "2022-06-01\n"
     ]
    }
   ],
   "source": [
    "#for i, sessionDate in newSessions.iteritems():\n",
    "#    print(sessionDate.date())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # dict(zip(vocabFromLesson,dateColumn))\n",
    "\n",
    "    df_dictionary = pd.DataFrame(lessonDictionary, columns=['Characters', 'Date'])\n",
    "\n",
    "    # print(df_dictionary.head())\n",
    "    vocab_df = pd.concat([vocab_df, df_dictionary], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adds new words\n",
    "def new_vocab_df_generator(elem):\n",
    "    \"\"\"_summary_\n",
    "    \n",
    "    Takes in an xml element, returns a dataframe of the chinese characters in each element\n",
    "    along with the date\n",
    "    \n",
    "    Added\n",
    "    \n",
    "    Args:\n",
    "        elem (_type_): _description_\n",
    "        xml element, expected to be in the opml format from workflowy\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_df = pd.DataFrame({}, columns=['Characters', 'Date'])\n",
    "\n",
    "    for i, lessonNotes in new_sessions.iter:\n",
    "\n",
    "        vocabFromLesson = []\n",
    "\n",
    "        # print(elementsDateAdded[i])\n",
    "        for note in lessonNotes:\n",
    "            noteText = note.attrib['text']\n",
    "\n",
    "            chineseCharacters = ''\n",
    "\n",
    "            for char in noteText:\n",
    "                if is_cjk(char):\n",
    "                    chineseCharacters += char\n",
    "\n",
    "            vocabFromLesson.append(chineseCharacters)\n",
    "\n",
    "        # Generates a column of same shape as vocab\n",
    "        dateColumn = [elementsDateAdded[i]] * len(vocabFromLesson)\n",
    "        lessonDictionary = {'Characters': vocabFromLesson,\n",
    "                            'Date': dateColumn}\n",
    "        # dict(zip(vocabFromLesson,dateColumn))\n",
    "\n",
    "        df_dictionary = pd.DataFrame(lessonDictionary, columns=['Characters', 'Date'])\n",
    "\n",
    "        return df_dictionary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_438088/2671166771.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtutorSessionDateSeries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.where(vocab_df['Date'].isin(tutorSessionDateSeries) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
